<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ONNX Model Inference with Image Input</title>
  <!-- Include onnxjs library -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.16.3/ort.webgpu.min.js"></script>
</head>

<body>
  <canvas id="imageCanvas" width="135" height="39"></canvas>
  <input type="file" id="imageInput" accept="image/*" onchange="loadImage()">

  <script>

    async function loadImage() {
      const session = await ort.InferenceSession.create("/model.onnx");
      const inputElement = document.getElementById('imageInput');
      const canvas = document.getElementById('imageCanvas');
      const ctx = canvas.getContext('2d', { alpha: false });

      const file = inputElement.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = function (e) {
          const img = new Image();
          img.onload = function () {
            // Draw the image onto the canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

            // Convert the image data to a tensor
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height).data;
            // remove alpha channel
            let pixels = []
            for (let i = 0; i < imageData.length; i += 4) {
              pixels.push(imageData[i])
              pixels.push(imageData[i + 1])
              pixels.push(imageData[i + 2])
            }
            // Normalize the pixels [0, 255] to be between [-1, 1].
            const mean = 127.5;
            const std = 128;
            pixels = pixels.map(val => (val - mean) / std);
            // 轉換為 C x H x W 格式
            const transposedImage = new Float32Array(3 * canvas.height * canvas.width);
            for (let c = 0; c < 3; c++) {
              for (let h = 0; h < canvas.height; h++) {
                for (let w = 0; w < canvas.width; w++) {
                  // 計算在 transposedImage 中的索引
                  const index = c * canvas.height * canvas.width + h * canvas.width + w;

                  // 計算在 image 中的索引
                  const originalIndex = h * canvas.width * 3 + w * 3 + c;

                  // 將數據從 np_img 複製到 transposedImage
                  transposedImage[index] = pixels[originalIndex];
                }
              }
            }

            const inputTensor = new ort.Tensor('float32', new Float32Array(transposedImage), [1, 3, canvas.height, canvas.width]);

            // Run inference
            session.run({ input: inputTensor }).then((output) => {
              // output.output.data is length 26*4 of possible alphabets
              let possibleAlphabets = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
              let outputString = "";
              for (let i = 0; i < 4; i += 1) {
                let max = -100;
                let maxIndex = 0;
                for (let j = 0; j < 26; j++) {
                  if (output.output.data[i * 26 + j] > max) {
                    max = output.output.data[i * 26 + j];
                    maxIndex = j;
                  }
                }
                outputString += possibleAlphabets[maxIndex];
              }
              console.log("Output string:", outputString);
            }).catch((err) => {
              console.error("Error running inference:", err);
            });
          };
          img.src = e.target.result;
        };
        reader.readAsDataURL(file);
      }
    }
  </script>
</body>

</html>